import copy

import os
import urllib.request
from urllib.error import HTTPError

import matplotlib
import matplotlib.pyplot as plt
import pytorch_lightning as pl
import seaborn as sns
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.utils.data as data
import torchvision
from IPython.display import set_matplotlib_formats
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint
from torchvision import transforms
from torchvision.datasets import CIFAR10
from torchvision.datasets import ImageFolder
from torchvision.transforms import ToTensor
from simple_ex_wandb import dataset_split, data_loader
from torch.utils.data import DataLoader, random_split
from torchmetrics import Accuracy
from pytorch_lightning.loggers import WandbLogger
import numpy as np
from data_1 import pool_dataloader1
import csv
import os
import random
from argparse import ArgumentParser
from copy import deepcopy
from dataclasses import dataclass

import numpy as np
import torch
import torch.backends
import torch.nn as nn
import torch.optim as optim
from torch import optim
from torch.hub import load_state_dict_from_url
from torch.nn import CrossEntropyLoss
from torchvision import datasets, models
from torchvision.models import vgg16
from torchvision.transforms import transforms
from tqdm.auto import tqdm
from tqdm.autonotebook import tqdm
import torch
from torch import nn, optim
from baal.modelwrapper import ModelWrapper
from torchvision.models import vgg16
from baal.bayesian.dropout import MCDropoutModule
from baal.active.heuristics import BALD, Entropy
from baal.active import ActiveLearningDataset, get_heuristic
from baal.active.active_loop import ActiveLearningLoop
from baal.bayesian.dropout import patch_module
from baal.modelwrapper import ModelWrapper
from baal.utils.metrics import Accuracy
from baal.ensemble import EnsembleModelWrapper
import os
import torch
import torchvision
import tarfile
from torchvision.datasets.utils import download_url
from torch.utils.data import random_split
from torchvision.datasets import ImageFolder
from baal.active import FileDataset, ActiveLearningDataset
from torchvision import transforms
from glob import glob
import os
from baal.utils.pytorch_lightning import (
    ActiveLightningModule,
    ResetCallback,
    BaalTrainer,
    BaaLDataModule
)

classes = ("crazing", "inclusion", "patches", "pitted_surface", "rolled-in_scale", "scratches")

'''
The FileDataset class is a PyTorch dataset object that loads files and applies transformations to them.
It takes in a list of file paths, optional labels, and various transformation functions.
The __len__ method returns the number of files in the dataset, and the __getitem__ method loads and transforms
a single file based on its index. The label method allows for the assignment of labels to files after initialization.
The get_kwargs method extracts any necessary keyword arguments for the transformation function.
'''

# Data path and Transforms Section
VALID_DIR = "/home/achazhoor/PycharmProjects/steel_classification/Test"
TRAIN_DIR = glob("/home/achazhoor/PycharmProjects/steel_classification/Train/*/*.bmp")
test_transform = transforms.Compose([transforms.ToTensor()])
train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),
                                      transforms.RandomApply(
                                          [transforms.ColorJitter(brightness=0.5, contrast=0.5,
                                                                  saturation=0.5, hue=0.1)], p=0.5),
                                      transforms.GaussianBlur(kernel_size=5),
                                      transforms.ToTensor(),
                                      transforms.Normalize((0.4934, 0.4934, 0.4934), (0.2243, 0.2243, 0.2243))
                                      ])

# Section place for Imagefolder instance on test and val datasets
dataset_test = ImageFolder(VALID_DIR, transform=test_transform)
# Splitting Val and Test sets
test_set_size = int(
    len(dataset_test) * 0.2)  # we divide the test set into test and validation keeping the train size more from previous
valid_set_size = len(dataset_test) - test_set_size
seed = torch.Generator().manual_seed(42)
test_set, valid_set = random_split(dataset_test, [test_set_size, valid_set_size], generator=seed)
val_dl = DataLoader(valid_set, batch_size=16, shuffle=False, num_workers=0)
test_dl = DataLoader(test_set, batch_size=16, shuffle=False, num_workers=0)


# Everything on Train_dataset

def get_label(img_path):
    return classes.index(img_path.split('/')[-2])


# def custom_dl():
#    global pool, pool_loader

train_dataset = FileDataset(TRAIN_DIR, [-1] * len(TRAIN_DIR), train_transform)
active_set = ActiveLearningDataset(train_dataset, pool_specifics={'transform': test_transform})
train_idxs = np.random.permutation(np.arange(len(train_dataset)))[:240].tolist()  # label 20% data
labels = [get_label(train_dataset.files[idx]) for idx in train_idxs]
active_set.label(train_idxs, labels)
train_loader = DataLoader(active_set, batch_size=64, num_workers=0, shuffle=True)


# return train_loader, pool_loader


# train_dl, pool = custom_dl()
# custom_dl().train_dataset


# Shape code below
# for batch_idx, (data, target) in enumerate(train_dl):
#     if batch_idx == 0:
#         print("shape is ", data.shape)
#         print("Target is", target)
#         break
#
# for batch_idx, (data, target) in enumerate(pool_dl):
#     if batch_idx == 0:
#         print("shape is ", data.shape)
#         print("Target is", target)
#         break


# ALl the names of the dataloader
# train_dl, val_dl and test_dl

# image will be divided into  patches because the dims in 200x200 -- we will get each image patch of 25x25
def img_to_patch(x, patch_size, flatten_channels=True):
    """
    Inputs:
        x - Tensor representing the image of shape [B, C, H, W]
        patch_size - Number of pixels per dimension of the patches (integer)
        flatten_channels - If True, the patches will be returned in a flattened format
                           as a feature vector instead of a image grid.

       This is a Python function that takes an input image tensor x of shape [B, C, H, W]
        and converts it into a tensor of patches of size patch_size of shape [B, H' * W', C * p_H * p_W],
        where H' = H // patch_size and W' = W // patch_size.

        If the img_to_patch function is called with an input image tensor of size 32x32 with 3 channels,
        and patch_size=8, the output will be a tensor of size [1, 16, 192] if flatten_channels=True,
        or [1, 16, 3, 64] if flatten_channels=False.
    """

    B, C, H, W = x.shape
    x = x.reshape(B, C, H // patch_size, patch_size, W // patch_size, patch_size)
    x = x.permute(0, 2, 4, 1, 3, 5)  # [B, H', W', C, p_H, p_W]
    x = x.flatten(1, 2)  # [B, H'*W', C, p_H, p_W]
    if flatten_channels:
        x = x.flatten(2, 4)  # [B, H'*W', C*p_H*p_W]
    return x


# we are using a pre layer normalization for this transformer
        self.input_layer = nn.Linear(num_channels * (patch_size ** 2), embed_dim)
        self.transformer = nn.Sequential(
            *(AttentionBlock(embed_dim, hidden_dim, num_heads, dropout=dropout) for _ in range(num_layers))
        )
        self.mlp_head = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, num_classes))
        self.dropout = nn.Dropout(dropout)

        # Parameters/Embeddings
        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))
        self.pos_embedding = nn.Parameter(torch.randn(1, 1 + num_patches, embed_dim))

    def forward(self, x):
        # Preprocess input
        x = img_to_patch(x, self.patch_size)  # x has a shape of (batch_size, seq_len, embedding_dim)
        parser.add_argument("--iterations", type=int, default=1, help="NUmber of MC Sampling to perform")
        parser.add_argument("--replicate_in_memory", type=bool, default=False)
        parser.add_argument("--batch_size", type=int, default=2)
        return parser


from argparse import ArgumentParser


def parse_arguments():
    parser = ArgumentParser()
    parser = ViT.add_model_specific_args(parser)
    parser = ArgumentParser(parents=[parser], add_help=False)
    parser.add_argument("--query_size", type=int, default=20, help="how many items to label per step")
    parser.add_argument("--heuristic", type=str, default="entropy", help="which heuristic to use")
    return parser.parse_args()


def train_model(**kwargs):
    args = parse_arguments()
    model = ViT(**kwargs, **vars(args))
    heuristic = get_heuristic(args.heuristic, shuffle_prop=0.0)
    wandb_logger = WandbLogger(name="vit_AL_11", project='Vision_Transformers_AL')

    trainer = BaalTrainer.from_argparse_args(args,
                                             dataset=TRAIN_DIR,
                                             gpus=1,
                                             # accelerator="gpu",  # if str(device) == "cuda:0" else 0,
                                             devices=1,
                                             # max_epochs=10,
                                             # strategy="ddp",
                                             max_epochs=2,
                                             heuristic=heuristic,
                                             query_size=args.query_size,
                                             logger=wandb_logger,
                                             callbacks=[ResetCallback(copy.deepcopy(model.state_dict())),
                                                        # ModelCheckpoint(save_top_k=1, save_weights_only=True,
                                                        #                 mode="max",
                                                        #                 monitor="val_acc"),
                                                        # LearningRateMonitor("epoch"),
                                                        ]
                                             )

    AL_STEPS = 150
    for al_step in range(AL_STEPS):
        print("for loop begins here------")
        pool = active_set.pool
        pool_loader = DataLoader(pool, batch_size=2, num_workers=0, shuffle=False)
        if len(pool) == 0:
            print("We're done!")
            break
        trainer.fit(model, train_loader, val_dl)
        trainer.test(model, test_dl)
        should_continue = trainer.predict_on_dataset(
            model, pool_loader)
        top_uncertainty = heuristic(should_continue)[:20]
        oracle_indices_labelled = active_set._pool_to_oracle_index(top_uncertainty)
        labels_l = [get_label(train_dataset.files[idx]) for idx in oracle_indices_labelled]
        active_set.label(top_uncertainty, labels_l)
        print("pool-----", len(pool))
        val_result = trainer.test(model, dataloaders=val_dl, verbose=False)
        test_result = trainer.test(model, dataloaders=test_dl, verbose=False)
        result = {"test": test_result[0]["test_acc"], "val": val_result[0]["test_acc"]}
        trainer.fit(model, train_loader, val_dl)

        # if not should_continue:
        #   break
    return model, result


if __name__ == '__main__':
    model, results = train_model(
        model_kwargs={
            "embed_dim": 256,
            "hidden_dim": 512,
            "num_heads": 8,
            "num_layers": 6,
            "patch_size": 8,
            "num_channels": 3,
            "num_patches": 625,
            "num_classes": 6,
            "dropout": 0.2,
        },
        lr=3e-4,
    )
# print("ViT results", results)
